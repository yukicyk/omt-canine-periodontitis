ss_model    <- permanova_res$SumOfSqs[1]
df_model    <- permanova_res$Df[1]
ss_residual <- permanova_res$SumOfSqs[2]
df_residual <- permanova_res$Df[2]
ms_residual <- ss_residual / df_residual
ss_total    <- sum(ss_model, ss_residual)
omega_sq_value <- (ss_model - (df_model * ms_residual)) / (ss_total + ms_residual)
# --- 4.3.3: Perform bootstrapping to calculate POWER ---
print(paste("... running", n_boots, "bootstrap iterations for power calculation ..."))
significant_p_count <- 0
# Convert rownames to a column to prevent them from being lost during sampling.
sub_meta_with_ids <- sub_meta %>% tibble::rownames_to_column("original_sample_id")
# Convert rownames to a column to prevent them from being lost during sampling.
sub_meta_with_ids <- sub_meta %>% tibble::rownames_to_column("original_sample_id")
for (i in 1:n_boots) {
if (i %% 10 == 0 || i == n_boots) {
cat("\rProgress: ", i, "/", n_boots)
}
# Bootstrap the metadata table. This creates the correct data frame for the adonis2 call.
boot_meta <- sub_meta_with_ids %>%
group_by(Group) %>%
slice_sample(prop = 1, replace = TRUE) %>%
ungroup()
# Pull the protected original sample IDs from the bootstrapped table.
# This is the key step to get the correct names for the distance matrix.
boot_sample_names <- boot_meta$original_sample_id
# Create the bootstrapped distance matrix using the CORRECT names
boot_dist <- as.dist(sub_dist_matrix[boot_sample_names, boot_sample_names])
# Run PERMANOVA on the bootstrapped data
boot_permanova <- adonis2(boot_dist ~ Group, data = boot_meta, permutations = 1)
if (boot_permanova$`Pr(>F)`[1] < alpha) {
significant_p_count <- significant_p_count + 1
}
}
# --- NEW: Print a new line after the progress bar is finished ---
cat("\n")
# Power is the proportion of significant results
calculated_power <- significant_p_count / n_boots
print(paste("Calculated Power:", calculated_power))
# --- 4.3.4: Store all results ---
power_results_list[[comp_name]] <- data.frame(
Comparison = comp_name,
DF = permanova_res$Df[1],
pseudo_F = permanova_res$F[1],
R2 = permanova_res$R2[1],
p_value = permanova_res$`Pr(>F)`[1],
omega_sq = omega_sq_value,
power = calculated_power
)
print("--- Comparison complete ---")
cat("\n") # Add a space before the next comparison starts
}
View(full_meta)
# Step 4.2: Define the comparisons to be tested.
comparisons <- list(
"All_Control_vs_Test"      = list(filter_col = "Treatment", groups = c("Control", "Recipient")),
"Wk-2_Control_vs_Test" = list(filter_col = "Treatment", groups = c("Control", "Recipient"), time_filter = "T1"),
"Baseline_Control_vs_Test"      = list(filter_col = "Treatment", groups = c("Control", "Recipient"), time_filter = "T2"),
"Wk2_Control_vs_Test"     = list(filter_col = "Treatment", groups = c("Control", "Recipient"), time_filter = "T3"),
"Wk12_Control_vs_Test"     = list(filter_col = "Treatment", groups = c("Control", "Recipient"), time_filter = "T4"),
"Control_Baseline_vs_Wk2"      = list(filter_col = "Timepoint",      groups = c("T2", "T3"), treatment_filter = "Control"),
"Test_Baseline_vs_Wk2"         = list(filter_col = "Timepoint",      groups = c("T2", "T3"), treatment_filter = "Recipient")
)
# Step 4.3: Loop through each comparison, run PERMANOVA, and calculate power via bootstrapping.
power_results_list <- list()
set.seed(42) # for reproducibility of the entire analysis
n_boots <- 99 # (999) Number of bootstrap iterations for power calculation
alpha <- 0.05 # Significance level
# --- NEW: Get the total number of comparisons for progress reporting ---
total_comparisons <- length(comparisons)
current_comparison_num <- 0
for (comp_name in names(comparisons)) {
current_comparison_num <- current_comparison_num + 1
print(paste0("--- Analyzing Comparison ", current_comparison_num, " of ", total_comparisons, ": '", comp_name, "' ---"))
# --- 4.3.1: Subset the data for the current comparison ---
comp_info <- comparisons[[comp_name]]
sub_meta <- full_meta
if (!is.null(comp_info$time_filter)) {
sub_meta <- sub_meta %>% filter(Timepoint %in% comp_info$time_filter)
}
if (!is.null(comp_info$treatment_filter)) {
sub_meta <- sub_meta %>% filter(Treatment %in% comp_info$treatment_filter)
}
sub_meta <- sub_meta %>% filter(.data[[comp_info$filter_col]] %in% comp_info$groups)
sub_meta$Group <- factor(sub_meta[[comp_info$filter_col]])
# Check if the filtered data contains at least two groups to compare.
if (length(levels(sub_meta$Group)) < 2) {
print(paste("!!! SKIPPING COMPARISON:", comp_name, "!!! Reason: After filtering, data for only one group was found. Cannot perform comparison."))
cat("\n")
next # Skip to the next iteration of the loop
}
sample_names <- rownames(sub_meta)
sub_dist_matrix <- dist_bc[sample_names, sample_names]
# --- 4.3.2: Calculate OBSERVED statistics from the REAL data ---
print("Calculating observed statistics from real data...")
permanova_res <- adonis2(as.dist(sub_dist_matrix) ~ Group, data = sub_meta, permutations = 9) #permutations should be set at 999, this is for test-run only
# Manually calculate Omega-Squared for the observed data
ss_model    <- permanova_res$SumOfSqs[1]
df_model    <- permanova_res$Df[1]
ss_residual <- permanova_res$SumOfSqs[2]
df_residual <- permanova_res$Df[2]
ms_residual <- ss_residual / df_residual
ss_total    <- sum(ss_model, ss_residual)
omega_sq_value <- (ss_model - (df_model * ms_residual)) / (ss_total + ms_residual)
# --- 4.3.3: Perform bootstrapping to calculate POWER ---
print(paste("... running", n_boots, "bootstrap iterations for power calculation ..."))
significant_p_count <- 0
# Convert rownames to a column to prevent them from being lost during sampling.
sub_meta_with_ids <- sub_meta %>% tibble::rownames_to_column("original_sample_id")
# Convert rownames to a column to prevent them from being lost during sampling.
sub_meta_with_ids <- sub_meta %>% tibble::rownames_to_column("original_sample_id")
for (i in 1:n_boots) {
if (i %% 10 == 0 || i == n_boots) {
cat("\rProgress: ", i, "/", n_boots)
}
# Bootstrap the metadata table. This creates the correct data frame for the adonis2 call.
boot_meta <- sub_meta_with_ids %>%
group_by(Group) %>%
slice_sample(prop = 1, replace = TRUE) %>%
ungroup()
# Pull the protected original sample IDs from the bootstrapped table.
# This is the key step to get the correct names for the distance matrix.
boot_sample_names <- boot_meta$original_sample_id
# Create the bootstrapped distance matrix using the CORRECT names
boot_dist <- as.dist(sub_dist_matrix[boot_sample_names, boot_sample_names])
# Run PERMANOVA on the bootstrapped data
boot_permanova <- adonis2(boot_dist ~ Group, data = boot_meta, permutations = 1)
if (boot_permanova$`Pr(>F)`[1] < alpha) {
significant_p_count <- significant_p_count + 1
}
}
# --- NEW: Print a new line after the progress bar is finished ---
cat("\n")
# Power is the proportion of significant results
calculated_power <- significant_p_count / n_boots
print(paste("Calculated Power:", calculated_power))
# --- 4.3.4: Store all results ---
power_results_list[[comp_name]] <- data.frame(
Comparison = comp_name,
DF = permanova_res$Df[1],
pseudo_F = permanova_res$F[1],
R2 = permanova_res$R2[1],
p_value = permanova_res$`Pr(>F)`[1],
omega_sq = omega_sq_value,
power = calculated_power
)
print("--- Comparison complete ---")
cat("\n") # Add a space before the next comparison starts
}
# Step 4.4: Combine results into a final table and save it.
power_summary_table <- bind_rows(power_results_list)
print("--- PERMANOVA Power Analysis Summary ---")
print(power_summary_table, row.names = FALSE)
write.csv(power_summary_table, file.path(table_path, "permanova_power_analysis_summary.csv"), row.names = FALSE)
n_boots <- 999 # (999) Number of bootstrap iterations for power calculation
alpha <- 0.05 # Significance level
# --- NEW: Get the total number of comparisons for progress reporting ---
total_comparisons <- length(comparisons)
current_comparison_num <- 0
for (comp_name in names(comparisons)) {
current_comparison_num <- current_comparison_num + 1
print(paste0("--- Analyzing Comparison ", current_comparison_num, " of ", total_comparisons, ": '", comp_name, "' ---"))
# --- 4.3.1: Subset the data for the current comparison ---
comp_info <- comparisons[[comp_name]]
sub_meta <- full_meta
if (!is.null(comp_info$time_filter)) {
sub_meta <- sub_meta %>% filter(Timepoint %in% comp_info$time_filter)
}
if (!is.null(comp_info$treatment_filter)) {
sub_meta <- sub_meta %>% filter(Treatment %in% comp_info$treatment_filter)
}
sub_meta <- sub_meta %>% filter(.data[[comp_info$filter_col]] %in% comp_info$groups)
sub_meta$Group <- factor(sub_meta[[comp_info$filter_col]])
# Check if the filtered data contains at least two groups to compare.
if (length(levels(sub_meta$Group)) < 2) {
print(paste("!!! SKIPPING COMPARISON:", comp_name, "!!! Reason: After filtering, data for only one group was found. Cannot perform comparison."))
cat("\n")
next # Skip to the next iteration of the loop
}
sample_names <- rownames(sub_meta)
sub_dist_matrix <- dist_bc[sample_names, sample_names]
# --- 4.3.2: Calculate OBSERVED statistics from the REAL data ---
print("Calculating observed statistics from real data...")
permanova_res <- adonis2(as.dist(sub_dist_matrix) ~ Group, data = sub_meta, permutations = 999) #permutations should be set at 999, this is for test-run only
# Manually calculate Omega-Squared for the observed data
ss_model    <- permanova_res$SumOfSqs[1]
df_model    <- permanova_res$Df[1]
ss_residual <- permanova_res$SumOfSqs[2]
df_residual <- permanova_res$Df[2]
ms_residual <- ss_residual / df_residual
ss_total    <- sum(ss_model, ss_residual)
omega_sq_value <- (ss_model - (df_model * ms_residual)) / (ss_total + ms_residual)
# --- 4.3.3: Perform bootstrapping to calculate POWER ---
print(paste("... running", n_boots, "bootstrap iterations for power calculation ..."))
significant_p_count <- 0
# Convert rownames to a column to prevent them from being lost during sampling.
sub_meta_with_ids <- sub_meta %>% tibble::rownames_to_column("original_sample_id")
# Convert rownames to a column to prevent them from being lost during sampling.
sub_meta_with_ids <- sub_meta %>% tibble::rownames_to_column("original_sample_id")
for (i in 1:n_boots) {
if (i %% 10 == 0 || i == n_boots) {
cat("\rProgress: ", i, "/", n_boots)
}
# Bootstrap the metadata table. This creates the correct data frame for the adonis2 call.
boot_meta <- sub_meta_with_ids %>%
group_by(Group) %>%
slice_sample(prop = 1, replace = TRUE) %>%
ungroup()
# Pull the protected original sample IDs from the bootstrapped table.
# This is the key step to get the correct names for the distance matrix.
boot_sample_names <- boot_meta$original_sample_id
# Create the bootstrapped distance matrix using the CORRECT names
boot_dist <- as.dist(sub_dist_matrix[boot_sample_names, boot_sample_names])
# Run PERMANOVA on the bootstrapped data
boot_permanova <- adonis2(boot_dist ~ Group, data = boot_meta, permutations = 1)
if (boot_permanova$`Pr(>F)`[1] < alpha) {
significant_p_count <- significant_p_count + 1
}
}
# --- NEW: Print a new line after the progress bar is finished ---
cat("\n")
# Power is the proportion of significant results
calculated_power <- significant_p_count / n_boots
print(paste("Calculated Power:", calculated_power))
# --- 4.3.4: Store all results ---
power_results_list[[comp_name]] <- data.frame(
Comparison = comp_name,
DF = permanova_res$Df[1],
pseudo_F = permanova_res$F[1],
R2 = permanova_res$R2[1],
p_value = permanova_res$`Pr(>F)`[1],
omega_sq = omega_sq_value,
power = calculated_power
)
print("--- Comparison complete ---")
cat("\n") # Add a space before the next comparison starts
}
# Step 4.4: Combine results into a final table and save it.
power_summary_table <- bind_rows(power_results_list)
print("--- PERMANOVA Power Analysis Summary ---")
print(power_summary_table, row.names = FALSE)
write.csv(power_summary_table, file.path(table_path, "permanova_power_analysis_summary.csv"), row.names = FALSE)
# --- Explanatory Notes on the Output ---
cat("
### How to Interpret the PERMANOVA Power Analysis Table ###
This table provides a retrospective look at the statistical power for the key
comparisons in our study.
- **Comparison**: The specific groups being compared.
- **DF**: Degrees of Freedom for the test.
- **pseudo-F**: The F-statistic from the PERMANOVA test. A larger value indicates
a larger difference between groups compared to within groups.
- **R2**: The effect size. It represents the proportion of variance in the
dissimilarity matrix that is explained by the grouping factor.
- **p_value**: The probability of observing the data if there were no real
difference between the groups. A value < 0.05 is typically considered
statistically significant.
- **omega_sq (ω²)**: A less biased measure of effect size than R2. It provides a
more conservative estimate of the variance explained by the grouping.
- **power**: The key result. This is the estimated probability (from 0 to 1)
of detecting a true effect if one exists, given our sample size and the
observed effect size. A power of 0.8 or higher is generally considered good.
For example, a power of 0.99 for a comparison means that we had a 99% chance of
detecting a significant difference between the groups, which gives us high
confidence in the PERMANOVA result for that test.
\n")
print("---------------------------------------------------")
View(boot_permanova)
boot_permanova$`Pr(>F)`[1]
for (i in 1:n_boots) {
if (i %% 10 == 0 || i == n_boots) {
cat("\rProgress: ", i, "/", n_boots)
}
# Bootstrap the metadata table. This creates the correct data frame for the adonis2 call.
boot_meta <- sub_meta_with_ids %>%
group_by(Group) %>%
slice_sample(prop = 1, replace = TRUE) %>%
ungroup()
# Pull the protected original sample IDs from the bootstrapped table.
# This is the key step to get the correct names for the distance matrix.
boot_sample_names <- boot_meta$original_sample_id
# Create the bootstrapped distance matrix using the CORRECT names
boot_dist <- as.dist(sub_dist_matrix[boot_sample_names, boot_sample_names])
# Run PERMANOVA on the bootstrapped data
boot_permanova <- adonis2(boot_dist ~ Group, data = boot_meta, permutations = 99)
if (boot_permanova$`Pr(>F)`[1] < alpha) {
significant_p_count <- significant_p_count + 1
}
}
n_boots <- 99 # (999) Number of bootstrap iterations for power calculation
alpha <- 0.05 # Significance level
# --- NEW: Get the total number of comparisons for progress reporting ---
total_comparisons <- length(comparisons)
current_comparison_num <- 0
for (comp_name in names(comparisons)) {
current_comparison_num <- current_comparison_num + 1
print(paste0("--- Analyzing Comparison ", current_comparison_num, " of ", total_comparisons, ": '", comp_name, "' ---"))
# --- 4.3.1: Subset the data for the current comparison ---
comp_info <- comparisons[[comp_name]]
sub_meta <- full_meta
if (!is.null(comp_info$time_filter)) {
sub_meta <- sub_meta %>% filter(Timepoint %in% comp_info$time_filter)
}
if (!is.null(comp_info$treatment_filter)) {
sub_meta <- sub_meta %>% filter(Treatment %in% comp_info$treatment_filter)
}
sub_meta <- sub_meta %>% filter(.data[[comp_info$filter_col]] %in% comp_info$groups)
sub_meta$Group <- factor(sub_meta[[comp_info$filter_col]])
# Check if the filtered data contains at least two groups to compare.
if (length(levels(sub_meta$Group)) < 2) {
print(paste("!!! SKIPPING COMPARISON:", comp_name, "!!! Reason: After filtering, data for only one group was found. Cannot perform comparison."))
cat("\n")
next # Skip to the next iteration of the loop
}
sample_names <- rownames(sub_meta)
sub_dist_matrix <- dist_bc[sample_names, sample_names]
# --- 4.3.2: Calculate OBSERVED statistics from the REAL data ---
print("Calculating observed statistics from real data...")
permanova_res <- adonis2(as.dist(sub_dist_matrix) ~ Group, data = sub_meta, permutations = 999) #permutations should be set at 999, this is for test-run only
# Manually calculate Omega-Squared for the observed data
ss_model    <- permanova_res$SumOfSqs[1]
df_model    <- permanova_res$Df[1]
ss_residual <- permanova_res$SumOfSqs[2]
df_residual <- permanova_res$Df[2]
ms_residual <- ss_residual / df_residual
ss_total    <- sum(ss_model, ss_residual)
omega_sq_value <- (ss_model - (df_model * ms_residual)) / (ss_total + ms_residual)
# --- 4.3.3: Perform bootstrapping to calculate POWER ---
print(paste("... running", n_boots, "bootstrap iterations for power calculation ..."))
significant_p_count <- 0
# Convert rownames to a column to prevent them from being lost during sampling.
sub_meta_with_ids <- sub_meta %>% tibble::rownames_to_column("original_sample_id")
# Convert rownames to a column to prevent them from being lost during sampling.
sub_meta_with_ids <- sub_meta %>% tibble::rownames_to_column("original_sample_id")
for (i in 1:n_boots) {
if (i %% 10 == 0 || i == n_boots) {
cat("\rProgress: ", i, "/", n_boots)
}
# Bootstrap the metadata table. This creates the correct data frame for the adonis2 call.
boot_meta <- sub_meta_with_ids %>%
group_by(Group) %>%
slice_sample(prop = 1, replace = TRUE) %>%
ungroup()
# Pull the protected original sample IDs from the bootstrapped table.
# This is the key step to get the correct names for the distance matrix.
boot_sample_names <- boot_meta$original_sample_id
# Create the bootstrapped distance matrix using the CORRECT names
boot_dist <- as.dist(sub_dist_matrix[boot_sample_names, boot_sample_names])
# Run PERMANOVA on the bootstrapped data
boot_permanova <- adonis2(boot_dist ~ Group, data = boot_meta, permutations = 99)
if (boot_permanova$`Pr(>F)`[1] < alpha) {
significant_p_count <- significant_p_count + 1
}
}
# --- NEW: Print a new line after the progress bar is finished ---
cat("\n")
# Power is the proportion of significant results
calculated_power <- significant_p_count / n_boots
print(paste("Calculated Power:", calculated_power))
# --- 4.3.4: Store all results ---
power_results_list[[comp_name]] <- data.frame(
Comparison = comp_name,
DF = permanova_res$Df[1],
pseudo_F = permanova_res$F[1],
R2 = permanova_res$R2[1],
p_value = permanova_res$`Pr(>F)`[1],
omega_sq = omega_sq_value,
power = calculated_power
)
print("--- Comparison complete ---")
cat("\n") # Add a space before the next comparison starts
}
# Step 4.4: Combine results into a final table and save it.
power_summary_table <- bind_rows(power_results_list)
print("--- PERMANOVA Power Analysis Summary ---")
print(power_summary_table, row.names = FALSE)
write.csv(power_summary_table, file.path(table_path, "permanova_power_analysis_summary.csv"), row.names = FALSE)
# --- Explanatory Notes on the Output ---
cat("
### How to Interpret the PERMANOVA Power Analysis Table ###
This table provides a retrospective look at the statistical power for the key
comparisons in our study.
- **Comparison**: The specific groups being compared.
- **DF**: Degrees of Freedom for the test.
- **pseudo-F**: The F-statistic from the PERMANOVA test. A larger value indicates
a larger difference between groups compared to within groups.
- **R2**: The effect size. It represents the proportion of variance in the
dissimilarity matrix that is explained by the grouping factor.
- **p_value**: The probability of observing the data if there were no real
difference between the groups. A value < 0.05 is typically considered
statistically significant.
- **omega_sq (ω²)**: A less biased measure of effect size than R2. It provides a
more conservative estimate of the variance explained by the grouping.
- **power**: The key result. This is the estimated probability (from 0 to 1)
of detecting a true effect if one exists, given our sample size and the
observed effect size. A power of 0.8 or higher is generally considered good.
For example, a power of 0.99 for a comparison means that we had a 99% chance of
detecting a significant difference between the groups, which gives us high
confidence in the PERMANOVA result for that test.
\n")
print("---------------------------------------------------")
print("Preparing data for Genus-level analysis...")
# Step 5.1: Agglomerate taxa to the Genus level using tax_glom.
ps_genus <- tax_glom(ps, taxrank = "Genus", NArm = TRUE)
#QC CHECK - Evaluate the effect of removing unclassified taxa.
print("--- QC Check: Evaluating abundance loss from tax_glom(NArm=TRUE) ---")
# Calculate sums before and after agglomeration
sums_before <- sample_sums(ps)
sums_after <- sample_sums(ps_genus)
# Combine into a data frame for comparison
qc_df <- data.frame(
SampleID = names(sums_before),
Abundance_Before = sums_before,
Abundance_After = sums_after[names(sums_before)] # Ensure correct sample matching
) %>%
mutate(Percent_Retained = (Abundance_After / Abundance_Before) * 100)
# Calculate average retention
average_retention <- mean(qc_df$Percent_Retained)
# Print results and recommendations
print("Percentage of abundance retained per sample after removing taxa unclassified at Genus level:")
print(qc_df %>% select(SampleID, Percent_Retained) %>% arrange(Percent_Retained))
print(sprintf("Average abundance retained across all samples: %.2f%%.", average_retention))
if (average_retention > 90) {
print("QC PASSED: Average retention is high (>90%). It is safe to proceed.")
} else {
print("QC WARNING: Average retention is low (<90%). A significant portion of abundance is from taxa unclassified at the Genus level.")
print("RECOMMENDATION: Consider re-running with tax_glom(..., NArm = FALSE) to keep these taxa, or revisit the taxonomic classification pipeline to improve assignments.")
}
print("--------------------------------------------------------------------")
# Step 5.2: Extract the Genus-level abundance table(samples x taxa).
genus_abun <- as.data.frame(otu_table(transform_sample_counts(ps_genus, function(x) x / sum(x))))
# Step 5.3: Create a mapping to get clean, unique Genus names for column headers.
tax_key <- as.data.frame(tax_table(ps_genus)) %>%
tibble::rownames_to_column("ASV_ID") %>%
mutate(Genus_Name = ifelse(is.na(Genus) | Genus == "", paste0("Unassigned_Genus_", ASV_ID), as.character(Genus))) %>%
mutate(Genus_Name_Unique = make.names(Genus_Name, unique = TRUE))
# Step 5.4: Replace the ASV_ID column names with the clean Genus names.
current_colnames <- colnames(genus_abun)
new_colnames <- tax_key$Genus_Name_Unique[match(current_colnames, tax_key$ASV_ID)]
colnames(genus_abun) <- new_colnames
# Step 5.5: Move the sample names from rownames to a column for joining.
genus_abun_wide <- genus_abun %>%
tibble::rownames_to_column("SampleID")
# Step 5.6: Create the final, clean Genus-level analysis data frame.
analysis_df_genus <- meta %>%
inner_join(clinical_data, by = "SampleID") %>%
inner_join(genus_abun_wide, by = "SampleID")
# Check the resultant dataframe before proceeding
# Check is the rows are samples, columns are genera, content is the relative abundance of genus in a given sample.
head(analysis_df_genus)
print("Performing Genus-level correlation analysis with FDR correction...")
# Select the clinical variables and the new genus columns for correlation.
corr_matrix_input_genus <- analysis_df_genus %>%
select(PPD_mean, BOP_pc, plaque_pc, all_of(new_colnames))
corr_results_genus <- rcorr(as.matrix(corr_matrix_input_genus), type = "pearson")
# Function to flatten the rcorr object
flatten_rcorr <- function(rcorr_obj) {
r <- rcorr_obj$r %>% as.data.frame() %>% tibble::rownames_to_column("var1") %>% gather(var2, r, -var1)
p <- rcorr_obj$P %>% as.data.frame() %>% tibble::rownames_to_column("var1") %>% gather(var2, p, -var1)
left_join(r, p, by = c("var1", "var2"))
}
corr_table_genus <- flatten_rcorr(corr_results_genus)
# Filter for significant correlations, APPLYING FDR CORRECTION
significant_correlations_genus <- corr_table_genus %>%
filter(var1 %in% c("PPD_mean", "BOP_pc", "plaque_pc") & var2 %in% new_colnames) %>%
# Correct for multiple testing using Benjamini-Hochberg (FDR)
mutate(p_adj = p.adjust(p, method = "fdr")) %>%
filter(p_adj < 0.05) %>%
# Optional: filter for stronger correlations
filter(abs(r) > 0.3)
# Create a heatmap of significant correlations
if (nrow(significant_correlations_genus) > 0) {
heatmap_data <- significant_correlations_genus %>%
select(var1, var2, r) %>% # var1:clinical meta, var2: Genus
pivot_wider(names_from = var1, values_from = r, values_fill = 0) %>%
tibble::column_to_rownames("var2") #r-values stored
pheatmap(
heatmap_data,
cluster_rows = TRUE,
cluster_cols = FALSE,
display_numbers = TRUE,
fontsize_number = 8,
labels_col = c("mean PPD", "BOP %", "Plaque %"),
angle_col = ("0"),
main = "Significant Pearson Correlations (FDR < 0.05)\nGenus vs. Clinical Parameters",
filename = file.path(fig_path, "correlation_heatmap_fdr.png")
)
write.csv(significant_correlations, file.path(table_path, "significant_clinical_correlations_fdr.csv"))
} else {
print("No significant correlations found after FDR correction.")
}
write.csv(significant_correlations_genus, file.path(table_path, "significant_clinical_correlations_fdr.csv"))
# Create a heatmap of significant correlations
if (nrow(significant_correlations_genus) > 0) {
heatmap_data <- significant_correlations_genus %>%
select(var1, var2, r) %>% # var1:clinical meta, var2: Genus
pivot_wider(names_from = var1, values_from = r, values_fill = 0) %>%
tibble::column_to_rownames("var2") #r-values stored
pheatmap(
heatmap_data,
cluster_rows = TRUE,
cluster_cols = FALSE,
display_numbers = TRUE,
fontsize_number = 8,
labels_col = c("mean PPD", "BOP %", "Plaque %"),
angle_col = ("0"),
main = "Significant Pearson Correlations (FDR < 0.05)\nGenus vs. Clinical Parameters",
filename = file.path(fig_path, "correlation_heatmap_fdr.png")
)
write.csv(significant_correlations_genus, file.path(table_path, "significant_clinical_correlations_fdr.csv"))
} else {
print("No significant correlations found after FDR correction.")
}
